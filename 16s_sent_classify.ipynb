{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec1c110-558f-4f76-b385-30525c7774df",
   "metadata": {},
   "source": [
    "### Get 16S sequence embedded into a model,may need to not use just a general language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9255ae5e-d982-4e59-9cfb-281e6f0d9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b285e6-3adc-4618-a76e-91f58616cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    keys = []\n",
    "    for key, value in my_dict.items():\n",
    "        if isinstance(value, list) and val in value:\n",
    "            keys.append(key)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa69935-3c40-4d32-9e5a-571ac08dec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2') # can i use a biological dna model from hugging face? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82ef3e5-ea91-408a-830f-6da835006280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGCTTCTTGGGTGTTGAGCGTGACC \t\t TGCGAACGTGGACCTGGTGCGAAGC \t\t Score: 0.9140\n",
      "CGTCCCGTTGCATATCACGAGAGCG \t\t CGACCGATGTCAAGAGCGCGCGCGT \t\t Score: 0.9005\n",
      "CGTCCCGTTGCATATCACGAGAGCG \t\t TGCGAACGTGGACCTGGTGCGAAGC \t\t Score: 0.8369\n",
      "TGCTTCTTGGGTGTTGAGCGTGACC \t\t CGTCCCGTTGCATATCACGAGAGCG \t\t Score: 0.8211\n",
      "CGACCGATGTCAAGAGCGCGCGCGT \t\t TGCGAACGTGGACCTGGTGCGAAGC \t\t Score: 0.8138\n"
     ]
    }
   ],
   "source": [
    "# Single list of sentences - Possible tens of thousands of sentences\n",
    "sentences = [\n",
    "    \"TGCTTCTTGGGTGTTGAGCGTGACC\",\n",
    "    \"GTGATCCCTTCGTAGCACCTGGGAA\",\n",
    "    \"GAGCTCGAATAGGTTATCAGAGCAG\",\n",
    "    \"CGACCGATGTCAAGAGCGCGCGCGT\",\n",
    "    \"TCTTACCTACTTGACTCTAGTGCGG\",\n",
    "    \"CCGACTGTTAGTCTCAGTTGTACTA\",\n",
    "    \"TGCGAACGTGGACCTGGTGCGAAGC\",\n",
    "    \"AGCTTGCGTGGATTCGTAGGGCTGG\",\n",
    "    \"CGTCCCGTTGCATATCACGAGAGCG\",\n",
    "    \"GGTTACACGTCTACTACTACATCCG\"]\n",
    "\n",
    "\n",
    "paraphrases = util.paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[0:5]:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d170a6c2-cd6c-4d9f-ab8c-ec92bb06202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GB_GCA_009371985.2</th>\n",
       "      <td>GAAGAGTTTGATCCTGGCTCAGGATGAACGCTAGCGGCAGGCCTAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_902705855.1</th>\n",
       "      <td>GGAGGTGATCCAGCCCCAGGTTCCCCTAGGGCTACCTTGTTACGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_000426325.1</th>\n",
       "      <td>AGGAGGTGATCCAGCCGCACCTTCCGGTACGGCTACCTTGTTACGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_004343615.1</th>\n",
       "      <td>TGAGAGTTTGATCCTGGCTCAGAGCGAACGCTGGCGGCATGCTTAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_010727475.1</th>\n",
       "      <td>AGGAGGTGATCCAGCCGCACCTTCCGGTACGGCTACCTTGTTACGA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             sequence\n",
       "id                                                                   \n",
       "GB_GCA_009371985.2  GAAGAGTTTGATCCTGGCTCAGGATGAACGCTAGCGGCAGGCCTAA...\n",
       "RS_GCF_902705855.1  GGAGGTGATCCAGCCCCAGGTTCCCCTAGGGCTACCTTGTTACGAC...\n",
       "RS_GCF_000426325.1  AGGAGGTGATCCAGCCGCACCTTCCGGTACGGCTACCTTGTTACGA...\n",
       "RS_GCF_004343615.1  TGAGAGTTTGATCCTGGCTCAGAGCGAACGCTGGCGGCATGCTTAA...\n",
       "RS_GCF_010727475.1  AGGAGGTGATCCAGCCGCACCTTCCGGTACGGCTACCTTGTTACGA..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your FASTA file\n",
    "fasta_file = \"data/ready4train_seqs.fasta\"\n",
    "\n",
    "# Parse the sequences and headers from the FASTA file\n",
    "records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "\n",
    "# Create a DataFrame from the sequences and headers\n",
    "df = pd.DataFrame([(record.id, str(record.seq)) for record in records],\n",
    "                  columns=[\"id\", \"sequence\"])\n",
    "df = df.set_index('id')\n",
    "# Print the first 10 rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a63bf08-cc2b-460c-ac59-5869d85c2dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seq_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RS_GCF_003697165.2</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Enterobacterales</td>\n",
       "      <td>Enterobacteriaceae</td>\n",
       "      <td>Escherichia</td>\n",
       "      <td>Escherichia coli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_001027105.1</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Staphylococcales</td>\n",
       "      <td>Staphylococcaceae</td>\n",
       "      <td>Staphylococcus</td>\n",
       "      <td>Staphylococcus aureus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_000006945.2</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Enterobacterales</td>\n",
       "      <td>Enterobacteriaceae</td>\n",
       "      <td>Salmonella</td>\n",
       "      <td>Salmonella enterica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_000742135.1</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Enterobacterales</td>\n",
       "      <td>Enterobacteriaceae</td>\n",
       "      <td>Klebsiella</td>\n",
       "      <td>Klebsiella pneumoniae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS_GCF_001457635.1</th>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Lactobacillales</td>\n",
       "      <td>Streptococcaceae</td>\n",
       "      <td>Streptococcus</td>\n",
       "      <td>Streptococcus pneumoniae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      domain          phylum                class  \\\n",
       "Seq_ID                                                              \n",
       "RS_GCF_003697165.2  Bacteria  Proteobacteria  Gammaproteobacteria   \n",
       "RS_GCF_001027105.1  Bacteria      Firmicutes              Bacilli   \n",
       "RS_GCF_000006945.2  Bacteria  Proteobacteria  Gammaproteobacteria   \n",
       "RS_GCF_000742135.1  Bacteria  Proteobacteria  Gammaproteobacteria   \n",
       "RS_GCF_001457635.1  Bacteria      Firmicutes              Bacilli   \n",
       "\n",
       "                               order              family           genus  \\\n",
       "Seq_ID                                                                     \n",
       "RS_GCF_003697165.2  Enterobacterales  Enterobacteriaceae     Escherichia   \n",
       "RS_GCF_001027105.1  Staphylococcales   Staphylococcaceae  Staphylococcus   \n",
       "RS_GCF_000006945.2  Enterobacterales  Enterobacteriaceae      Salmonella   \n",
       "RS_GCF_000742135.1  Enterobacterales  Enterobacteriaceae      Klebsiella   \n",
       "RS_GCF_001457635.1   Lactobacillales    Streptococcaceae   Streptococcus   \n",
       "\n",
       "                                     species  \n",
       "Seq_ID                                        \n",
       "RS_GCF_003697165.2          Escherichia coli  \n",
       "RS_GCF_001027105.1     Staphylococcus aureus  \n",
       "RS_GCF_000006945.2       Salmonella enterica  \n",
       "RS_GCF_000742135.1     Klebsiella pneumoniae  \n",
       "RS_GCF_001457635.1  Streptococcus pneumoniae  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy = pd.read_csv('data/train_taxonomy.tsv', sep='\\t', index_col = 0)\n",
    "taxonomy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "931a4d2b-d7a0-4436-a080-6a042164d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy['sequence'] = df['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef624bfb-c14f-4e2b-87d2-b83f2fe422d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows with at least two occurrences of the value in the \"genus\" column\n",
    "genus_counts = taxonomy['genus'].value_counts()\n",
    "genus_multiple_occurrences = genus_counts[genus_counts >= 2].index.tolist()\n",
    "df_subset = taxonomy[taxonomy['genus'].isin(genus_multiple_occurrences)]\n",
    "\n",
    "# Split the DataFrame into two subsets, test and ref, with about 50% of each genus value\n",
    "test = pd.DataFrame()\n",
    "ref = pd.DataFrame()\n",
    "for genus in genus_multiple_occurrences:\n",
    "    genus_subset = df_subset[df_subset['genus'] == genus]\n",
    "    n = len(genus_subset)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    split_idx = int(np.floor(n / 2))\n",
    "    test_idx = indices[:split_idx]\n",
    "    ref_idx = indices[split_idx:]\n",
    "    test = pd.concat([test, genus_subset.iloc[test_idx]])\n",
    "    ref = pd.concat([ref, genus_subset.iloc[ref_idx]])\n",
    "\n",
    "# Print the resulting DataFrames\n",
    "#print(test)\n",
    "#print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e8896c-c4a1-438c-9f58-41a6b8f17036",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1f4b52-6ed1-4e07-b534-70f0ff31bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant columns from the dataframes\n",
    "test_subset = test[['genus', 'sequence']][0:q]\n",
    "ref_subset = ref[['genus', 'sequence']][0:q]\n",
    "\n",
    "# Set genus column as index for text and ref dataframes\n",
    "test_subset.set_index('genus', inplace=True)\n",
    "ref_subset.set_index('genus', inplace=True)\n",
    "\n",
    "# Concatenate text and ref dataframes\n",
    "combined_df = pd.concat([test_subset, ref_subset])\n",
    "\n",
    "# Group sequences by genus\n",
    "seq_dict = combined_df.groupby('genus')['sequence'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65db76cc-86e2-4b1e-86ac-d253fcf3307f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 49730.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 1.0\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for evaluation metrics\n",
    "total_accuracy = 0\n",
    "count = 0\n",
    "\n",
    "test_list = test.sequence[0:q].tolist()\n",
    "ref_list = ref.sequence[0:q].tolist()\n",
    "\n",
    "# Single list of sentences - Possible tens of thousands of sentences\n",
    "sequences = test_list + ref_list\n",
    "paraphrases = util.paraphrase_mining(model, sequences)  \n",
    "\n",
    "# Group sublists by their second element (index 1)\n",
    "grouped_dict = {}\n",
    "for sublist in paraphrases:\n",
    "    key = sublist[1]\n",
    "    if key not in grouped_dict:\n",
    "        grouped_dict[key] = []\n",
    "    grouped_dict[key].append(sublist)\n",
    "\n",
    "# Get the two sublists with the greatest value in element 0 for each unique value in element 1\n",
    "result = []\n",
    "for key in sorted(grouped_dict.keys()):\n",
    "    sublists = grouped_dict[key]\n",
    "    top_two_sublists = sorted(sublists, key=lambda x: x[0], reverse=True)[:1]# can change to get more or less sentence matching\n",
    "    result.extend(top_two_sublists)\n",
    "\n",
    "# Replace indices with corresponding sentences\n",
    "for sublist in result:\n",
    "    sublist[1] = sequences[sublist[1]]\n",
    "    sublist[2] = sequences[sublist[2]]\n",
    "\n",
    "for seq in tqdm(test_list):\n",
    "    # Get all sublists where element 1 equals the match string\n",
    "    closest_match = [sublist[2] for sublist in result if ((sublist[1] == seq))]\n",
    "    correct_match = [key for key, values in seq_dict.items() if seq in values]\n",
    "    closest_match = get_key(seq_dict, closest_match[0])\n",
    "    accuracy = int(any(item in closest_match for item in correct_match))\n",
    "    \n",
    "    # Update evaluation metrics\n",
    "    total_accuracy += accuracy\n",
    "    count += 1\n",
    "    \n",
    "    #print(f\"Input taxa: {get_key(seq_dict, seq)}, closest match: {closest_match}, correct match: {correct_match}\")\n",
    "\n",
    "# Compute average evaluation metrics\n",
    "avg_accuracy = total_accuracy / count\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f30be0-f5fe-43f8-876f-e51352f7379e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 209296.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 1.0\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for evaluation metrics\n",
    "total_accuracy = 0\n",
    "count = 0\n",
    "\n",
    "test_list = test.sequence[0:q].tolist()\n",
    "ref_list = ref.sequence[0:q].tolist()\n",
    "\n",
    "# Single list of sentences - Possible tens of thousands of sentences\n",
    "sequences = test_list + ref_list\n",
    "paraphrases = util.paraphrase_mining(model, sequences)  \n",
    "\n",
    "# Group sublists by their second element (index 1)\n",
    "grouped_dict = {}\n",
    "for sublist in paraphrases:\n",
    "    key = sublist[1]\n",
    "    if key not in grouped_dict:\n",
    "        grouped_dict[key] = []\n",
    "    grouped_dict[key].append(sublist)\n",
    "\n",
    "# Get the two sublists with the greatest value in element 0 for each unique value in element 1\n",
    "result = []\n",
    "for key in sorted(grouped_dict.keys()):\n",
    "    sublists = grouped_dict[key]\n",
    "    top_two_sublists = sorted(sublists, key=lambda x: x[0], reverse=True)[:1]# can change to get more or less sentence matching\n",
    "    result.extend(top_two_sublists)\n",
    "\n",
    "# Replace indices with corresponding sentences\n",
    "for sublist in result:\n",
    "    sublist[1] = sequences[sublist[1]]\n",
    "    sublist[2] = sequences[sublist[2]]\n",
    "\n",
    "# Create a dictionary that maps each sequence to its closest match\n",
    "closest_match_dict = {}\n",
    "for seq in test_list:\n",
    "    # Get all sublists where element 1 equals the match string\n",
    "    closest_match = [sublist[2] for sublist in result if ((sublist[1] == seq))]\n",
    "    closest_match_dict[seq] = get_key(seq_dict, closest_match[0])\n",
    "\n",
    "# Compute accuracy for each test sequence\n",
    "for seq, closest_match in tqdm(closest_match_dict.items()):\n",
    "    correct_match = [key for key, values in seq_dict.items() if seq in values]\n",
    "    accuracy = int(any(item in closest_match for item in correct_match))\n",
    "    \n",
    "    # Update evaluation metrics\n",
    "    total_accuracy += accuracy\n",
    "    count += 1\n",
    "    \n",
    "    #print(f\"Input taxa: {get_key(seq_dict, seq)}, closest match: {closest_match}, correct match: {correct_match}\")\n",
    "\n",
    "# Compute average evaluation metrics\n",
    "avg_accuracy = total_accuracy / count\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy}\")\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b5f13-f7c3-4401-83d3-10331d292e0f",
   "metadata": {},
   "source": [
    "### can also try below with DNA sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083d86e-6c50-41e9-892a-713645a10a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Import the tokenizer and the model\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "\n",
    "# Create a dummy dna sequence and tokenize it\n",
    "sequences = test_list + ref_list\n",
    "tokens_ids = tokenizer.batch_encode_plus(sequences, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
    "\n",
    "# Compute the embeddings\n",
    "attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "torch_outs = model(\n",
    "    tokens_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    encoder_attention_mask=attention_mask,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "# Compute sequences embeddings\n",
    "embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings per token: {embeddings}\")\n",
    "\n",
    "# Compute mean embeddings per sequence\n",
    "mean_sequence_embeddings = torch.sum(attention_mask.unsqueeze(-1)*embeddings, axis=-2)/torch.sum(attention_mask, axis=-1)\n",
    "print(f\"Mean sequence embeddings: {mean_sequence_embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b6a34-2532-455f-8c19-60debd8259bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### need to get data andfind method to compare label to true or false label, or I can try to get database from green genes and then compare the ability of this method to the classification of greengenes using a real data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41cf24-c9c7-490b-9a7d-07bf7e5244b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy dna sequence and tokenize it\n",
    "sequences = \n",
    "tokens_ids = tokenizer.batch_encode_plus(sequences, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Compute the embeddings\n",
    "attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "torch_outs = model(\n",
    "    tokens_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    encoder_attention_mask=attention_mask,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "# Compute sequences embeddings\n",
    "embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings per token: {embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aabea4-e337-4664-a17e-1a2ed85ac656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import the tokenizer and the model\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "\n",
    "# Define a dictionary of reference sequences and their embeddings\n",
    "ref_sequences = {\n",
    "    \"ref_seq_1\": \"ATTCTG\" * 9,\n",
    "    \"ref_seq_2\": \"GTAGTC\" * 9,\n",
    "    \"ref_seq_3\": \"CTCGAT\" * 9\n",
    "}\n",
    "ref_embeddings = {}\n",
    "\n",
    "# Compute the embeddings for the reference sequences\n",
    "for name, seq in ref_sequences.items():\n",
    "    tokens_ids = tokenizer.encode(seq, return_tensors=\"pt\")\n",
    "    attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "    torch_outs = model(tokens_ids, attention_mask=attention_mask, encoder_attention_mask=attention_mask, output_hidden_states=True)\n",
    "    embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "    ref_embeddings[name] = np.mean(embeddings, axis=1)\n",
    "\n",
    "# Define a list of input sequences\n",
    "input_sequences = [\n",
    "    \"ATTCTG\" * 9,\n",
    "    \"AGAGTT\" * 9,\n",
    "    \"CTCGAT\" * 9\n",
    "]\n",
    "\n",
    "# Encode the input sequences and compute their embeddings\n",
    "input_tokens = tokenizer.batch_encode_plus(input_sequences, return_tensors=\"pt\", padding=True)\n",
    "input_embeddings = model(input_tokens['input_ids'], attention_mask=input_tokens['attention_mask'], encoder_attention_mask=input_tokens['attention_mask'], output_hidden_states=True)['hidden_states'][-1].detach().numpy()\n",
    "\n",
    "# Compute cosine similarity between input embeddings and reference embeddings\n",
    "cos_sim = cosine_similarity(input_embeddings, [ref_embeddings[name] for name in ref_sequences])\n",
    "\n",
    "# Find the closest reference sequence for each input sequence\n",
    "closest_seqs = [max(ref_sequences, key=lambda name: cos_sim[i][list(ref_sequences).index(name)]) for i in range(cos_sim.shape[0])]\n",
    "\n",
    "# Print the closest reference sequence for each input sequence\n",
    "for i, seq in enumerate(input_sequences):\n",
    "    print(f\"Input sequence {i+1}: {seq}\")\n",
    "    print(f\"Closest reference sequence: {closest_seqs[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973066cf-a0df-4e35-a3e8-9106a658c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reference sequences and compute embeddings\n",
    "ref_sequences = [\"ATCGATCG\", \"CGTAGCTA\", \"TTGACCTA\"]\n",
    "ref_embeddings = {}\n",
    "for seq in ref_sequences:\n",
    "    tokens_ids = tokenizer.encode(seq, return_tensors=\"pt\")\n",
    "    torch_outs = model(tokens_ids)\n",
    "    ref_embeddings[seq] = torch_outs.hidden_states[-1][0]\n",
    "\n",
    "# Create a dummy input sequence and compute its embedding\n",
    "input_sequence = \"CGTAGGCA\"\n",
    "input_ids = tokenizer.encode(input_sequence, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    model_output = model(input_ids)\n",
    "    input_embedding = model_output.hidden_states[-1][0]\n",
    "\n",
    "# Compute the cosine similarity between the input embedding and the reference sequence embeddings\n",
    "cos_sim = cosine_similarity(input_embedding.reshape(1, -1), [ref_embeddings[name] for name in ref_sequences])\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333bc94-189b-474a-8524-6e304f227d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_nlp",
   "language": "python",
   "name": "bio_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
